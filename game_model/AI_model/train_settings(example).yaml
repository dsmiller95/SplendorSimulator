learning_rate: 0.001 
gamma: 0.99 #discount factor, how much it cares about future reward vs current reward
            #(0: only current, 1: current and all future states)
epsilon: 0.5 #how often to pick the maximum-Q-valued action
memory_length: 10000      #number of rounds to play of the game
batch_size_multiplier: 1.0 #batch size is set to the average number of turns per game multiplied by this factor
max_batch_size: 1000 #so that we don't run out of memory accidentally
epochs: 100000 #how many play->learn cycles to run
hidden_layer_width: 128 #I like to keep things like linear layer widths at multiples of 2 for faster GPU processing
n_hidden_layers: 3

# Rewards: [use this reward?, value of this reward]
tokens_held: [False,1.0]
cards_held: [False,1.0]
points: [True,5.0]
win_lose: [True,200]
length_of_game: [True,-0.1]
